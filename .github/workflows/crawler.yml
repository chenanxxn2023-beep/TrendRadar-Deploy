name: Get Hot News

on:
  schedule:
    # æ¯å°æ—¶ç¬¬ 33 åˆ†è¿è¡Œ
    - cron: "33 * * * *"
  workflow_dispatch:

concurrency:
  group: crawler-${{ github.ref_name }}
  cancel-in-progress: true

permissions:
  contents: write    # å…è®¸å†™æ–‡ä»¶
  actions: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          clean: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify required files
        run: |
          if [ ! -f config/config.yaml ]; then
            echo "Error: Config missing"
            exit 1
          fi

      - name: Run crawler
        env:
          # æ‚¨çš„ Secrets ç¯å¢ƒå˜é‡
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          BARK_URL: ${{ secrets.BARK_URL }}
          AI_ANALYSIS_ENABLED: ${{ secrets.AI_ANALYSIS_ENABLED }}
          AI_API_KEY: ${{ secrets.AI_API_KEY }}
          AI_PROVIDER: ${{ secrets.AI_PROVIDER }}
          AI_MODEL: ${{ secrets.AI_MODEL }}
          GITHUB_ACTIONS: true
        run: python -m trendradar

      # ğŸ‘‡ğŸ‘‡ğŸ‘‡ ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ–°å¢ï¼šå¼ºåˆ¶å°† SQLite æ•°æ®åº“è½¬ä¸º JSON ğŸ‘‡ğŸ‘‡ğŸ‘‡
      - name: Export DB to JSON
        if: success()
        run: |
          cat <<EOF > export_json.py
          import sqlite3
          import json
          import glob
          import os
          
          try:
            # 1. æ‰¾åˆ° output/news/ ä¸‹æœ€æ–°çš„ db æ–‡ä»¶
            list_of_files = glob.glob('output/news/*.db')
            if not list_of_files:
                print("âš ï¸ No DB files found, skipping export.")
                exit(0)
            
            latest_file = max(list_of_files, key=os.path.getctime)
            print(f"ğŸ“– Reading Database: {latest_file}")
            
            conn = sqlite3.connect(latest_file)
            cursor = conn.cursor()
            
            # 2. è·å–æ‰€æœ‰è¡¨çš„æ•°æ®
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [t[0] for t in cursor.fetchall()]
            
            final_data = {}
            
            for table in tables:
                print(f"   Processing table: {table}")
                cursor.execute(f"SELECT * FROM {table}")
                cols = [description[0] for description in cursor.description]
                rows = cursor.fetchall()
                # è½¬ä¸ºå­—å…¸åˆ—è¡¨
                final_data[table] = [dict(zip(cols, row)) for row in rows]
            
            # 3. å†™å…¥ output/daily_hot_news.json
            output_file = 'output/daily_hot_news.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(final_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Successfully exported JSON to: {output_file}")
            
          except Exception as e:
            print(f"âŒ Error exporting JSON: {e}")
            exit(1)
          EOF
          
          # è¿è¡Œè½¬æ¢è„šæœ¬
          python export_json.py

      # æäº¤å¹¶ä¿å­˜ç»“æœ
      - name: Commit and push changes
        if: success()
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add output/
          git commit -m "Auto update data (with JSON)" -a || exit 0
          git push
